# MAPGD: Multi-Agent Prompt Gradient Descent for Collaborative Prompt Optimization
### ğŸ‘¨â€ğŸ’» Authors
- **Yichen Han** â€” South China Normal University, Guangzhou, China Â· [2024024502@m.scnu.edu.cn](mailto:2024024502@m.scnu.edu.cn)  
- **Yuhang Han** â€” Northwestern Polytechnical University, Xi'an, China Â· [hanyh@mail.nwpu.edu.cn](mailto:hanyh@mail.nwpu.edu.cn)  
- **Bojun Liu** â€” University of Sydney, Sydney, Australia Â· [liubojun9999@gmail.com](mailto:liubojun9999@gmail.com)  
- **Zhengpeng Zhou** â€” Shanghai Jiaotong University, Shanghai, China Â· [alex_chou@sjtu.edu.cn](mailto:alex_chou@sjtu.edu.cn)  
- **Guanyu Liu** â€” University of Macau, Macau, China Â· [dc32352@um.edu.mo](mailto:dc32352@um.edu.mo)  
- **Zeng Zhang** â€” South China Normal University, Guangzhou, China Â· [2024024588@m.scnu.edu.cn](mailto:2024024588@m.scnu.edu.cn)  
- **Yang Yang** â€” Silicon Sapiens LLC, Jinan, China Â· [yang@esapiens.ai](mailto:yang@esapiens.ai)  
- **Wenli Wang** â€” Silicon Sapiens LLC, Jinan, China Â· [wenli@esapiens.ai](mailto:wenli@esapiens.ai)  
- **Isaac N Shi** â€” Silicon Sapiens LLC, Jinan, China Â· [isaac@goldensection.com](mailto:isaac@goldensection.com)  
- **Yunyan Zhang** â€” Silicon Sapiens LLC, Jinan, China Â· [yunyan@fangyingmobile.com](mailto:yunyan@fangyingmobile.com)  
- **Lewei He** (âœ‰ï¸ Corresponding author) â€” South China Normal University, Guangzhou, China Â· [helewei@m.scnu.edu.cn](mailto:helewei@m.scnu.edu.cn)  
- **Tianyu Shi** (âœ‰ï¸ Corresponding author) â€” University of Toronto, Toronto, Canada Â· [tys@cs.toronto.edu](mailto:tys@cs.toronto.edu)  
---
## ğŸš€ Abstract
Prompt design critically affects the performance of large language models (LLMs). Existing optimization methods often rely on single-agent heuristics, which lack diversity, collaboration, and robustness.  
**MAPGD** introduces a multi-agent framework where each agent explores prompts from different perspectives, generates textual â€œgradients,â€ and collaboratively improves prompts via **beam search**, **semantic fusion**, and **bandit-based selection**.  
This approach improves diversity, semantic directionality, and interpretabilityâ€”offering a scalable and effective solution for real-world prompt engineering.
## ğŸ§© Core Idea

- **Multiple Agents** â†’ Explore diverse semantic directions  
- **Textual Gradients** â†’ Semantic feedback analogous to numerical gradients  
- **Gradient Fusion** â†’ Merge and align multiple prompt edits  
- **Beam Search** â†’ Expand candidate prompt space efficiently  
- **Bandit Selection** â†’ Identify best prompts with minimal evaluation cost  
## âš™ï¸ System Workflow

```text
Input: Initial prompt p0, datasets D_train / D_dev

Iterative Optimization:
  1. Agents propose textual gradients & edits
  2. Gradients are clustered & fused
  3. Candidate prompts expanded (beam + paraphrasing)
  4. Bandit-based selection chooses top prompts
  5. Agents sync with best candidate

Output: Optimized prompt

